{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35f976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import ast\n",
    "import os\n",
    "\n",
    "# YouTube API\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba6f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os. chdir('C:/Users/Esteban Guerrero/SocialNetworkProject/Iteration2/PythonScripts')\n",
    "%run ./DataProcessing_PrepareOutputIntoDF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf573a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os. chdir('C:/Users/Esteban Guerrero/SocialNetworkProject/Iteration2/PythonScripts')\n",
    "%run ./DataProcessing_TextPreparation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f666e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain latest list of videos per channel if video has comments and published after start period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f91b28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('C:/Users/Esteban Guerrero/SocialNetworkProject/Iteration2/Datasets/NetworkFeedRawOutput.csv', index_col = False, encoding = 'ISO-8859-1')\n",
    "df1 = df1[(df1.ExtrType == 'YouTubeVideoInfo') | (df1.ExtrType == 'VideoInfo-YouTube')].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "637e4039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sort_values(by = ['Key1', 'Key2', 'ExtractionDateTime'], ascending = True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82f6c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sort_values(by = ['Key1', 'Key2', 'ExtractionDateTime'], ascending = True).reset_index(drop = True)\n",
    "df1 = pd.concat([df1, df1.duplicated(keep = 'last', subset = ['Key1', 'Key2'])], axis = 1)\n",
    "df1.rename(columns ={0: 'DuplicateFlag'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5251319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1.DuplicateFlag == False].reset_index(drop = True)\n",
    "df1 = df1.drop(['DuplicateFlag'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c64812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['CommentCount'] = 0\n",
    "df1['publishedAt'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff44d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(df1.Output1)):\n",
    "#for i in range(0, 50):\n",
    "    df1.iat[i, 6] = ast.literal_eval(df1.iat[i, 2])['VideoStats'].get('commentCount')\n",
    "    df1.iat[i, 7] = ast.literal_eval(df1.iat[i, 2])['VideoDetails'].get('publishedAt')[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc9cb451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[(df1.CommentCount > 0) & (df1.CommentCount.notnull()) & (df1.CommentCount.notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b5699ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['publishedAt'] =  pd.to_datetime(df1['publishedAt'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e2708ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-04\n"
     ]
    }
   ],
   "source": [
    "ndays = 60\n",
    "start_date = (datetime.now()  - timedelta(ndays-1)).strftime(\"%Y-%m-%d\")\n",
    "print(start_date)\n",
    "df1 = df1[df1['publishedAt'] >= start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2550149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key1</th>\n",
       "      <th>Key2</th>\n",
       "      <th>Output1</th>\n",
       "      <th>ExtractionDateTime</th>\n",
       "      <th>ExtrMethod</th>\n",
       "      <th>ExtrType</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>publishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UC_vhdXDVvZQGMqQFDgn0w1g</td>\n",
       "      <td>-WPsW2uBtEg</td>\n",
       "      <td>{'User': 'Espert', 'VideoDetails': {'published...</td>\n",
       "      <td>2021-08-02 16:22:30 -0300</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>VideoInfo-YouTube</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2021-06-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>UC_vhdXDVvZQGMqQFDgn0w1g</td>\n",
       "      <td>00QjyVewlX0</td>\n",
       "      <td>{'User': 'Espert', 'VideoDetails': {'published...</td>\n",
       "      <td>2021-08-02 16:22:30 -0300</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>VideoInfo-YouTube</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2021-06-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>UC_vhdXDVvZQGMqQFDgn0w1g</td>\n",
       "      <td>3VgcwXK19Sg</td>\n",
       "      <td>{'User': 'Espert', 'VideoDetails': {'published...</td>\n",
       "      <td>2021-08-02 16:22:30 -0300</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>VideoInfo-YouTube</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2021-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>UC_vhdXDVvZQGMqQFDgn0w1g</td>\n",
       "      <td>3afCHxQ2fhs</td>\n",
       "      <td>{'User': 'Espert', 'VideoDetails': {'published...</td>\n",
       "      <td>2021-08-02 16:22:30 -0300</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>VideoInfo-YouTube</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2021-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>UC_vhdXDVvZQGMqQFDgn0w1g</td>\n",
       "      <td>3pdNGdVMR-k</td>\n",
       "      <td>{'User': 'Espert', 'VideoDetails': {'published...</td>\n",
       "      <td>2021-08-02 16:22:30 -0300</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>VideoInfo-YouTube</td>\n",
       "      <td>425.0</td>\n",
       "      <td>2021-06-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Key1         Key2  \\\n",
       "17   UC_vhdXDVvZQGMqQFDgn0w1g  -WPsW2uBtEg   \n",
       "32   UC_vhdXDVvZQGMqQFDgn0w1g  00QjyVewlX0   \n",
       "114  UC_vhdXDVvZQGMqQFDgn0w1g  3VgcwXK19Sg   \n",
       "118  UC_vhdXDVvZQGMqQFDgn0w1g  3afCHxQ2fhs   \n",
       "123  UC_vhdXDVvZQGMqQFDgn0w1g  3pdNGdVMR-k   \n",
       "\n",
       "                                               Output1  \\\n",
       "17   {'User': 'Espert', 'VideoDetails': {'published...   \n",
       "32   {'User': 'Espert', 'VideoDetails': {'published...   \n",
       "114  {'User': 'Espert', 'VideoDetails': {'published...   \n",
       "118  {'User': 'Espert', 'VideoDetails': {'published...   \n",
       "123  {'User': 'Espert', 'VideoDetails': {'published...   \n",
       "\n",
       "            ExtractionDateTime ExtrMethod           ExtrType  CommentCount  \\\n",
       "17   2021-08-02 16:22:30 -0300  Automatic  VideoInfo-YouTube          14.0   \n",
       "32   2021-08-02 16:22:30 -0300  Automatic  VideoInfo-YouTube          24.0   \n",
       "114  2021-08-02 16:22:30 -0300  Automatic  VideoInfo-YouTube          74.0   \n",
       "118  2021-08-02 16:22:30 -0300  Automatic  VideoInfo-YouTube          13.0   \n",
       "123  2021-08-02 16:22:30 -0300  Automatic  VideoInfo-YouTube         425.0   \n",
       "\n",
       "    publishedAt  \n",
       "17   2021-06-10  \n",
       "32   2021-06-28  \n",
       "114  2021-07-26  \n",
       "118  2021-07-26  \n",
       "123  2021-06-28  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dec6d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API\n",
    "youTubeApiKey = 'youTubeApiKey'\n",
    "youtube = build('youtube','v3', developerKey = youTubeApiKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8307a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract from API, video comments data per videoID and return comments dataframe\n",
    "\n",
    "def CommentsDataPerVideoID(vidID0, ChannelID01):\n",
    "\n",
    "    # 1 - Extract comments and replies from API per videoID\n",
    "    vidcomments0 = []\n",
    "    next_page_token = None\n",
    "    while 1:\n",
    "        res = youtube.commentThreads().list(part = 'snippet,replies', videoId = vidID0, \n",
    "                                            maxResults = 50, pageToken = next_page_token).execute()\n",
    "        vidcomments0+= res['items']\n",
    "        next_page_token = res.get('nextPageToken')\n",
    "\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    \n",
    "    # 2 - Create video comments dataframe and extract replies\n",
    "    vidCommentsDf0 = pd.DataFrame()\n",
    "    for m in range(0, len(vidcomments0)):\n",
    "        commentoutput = {'Output1': {'commentContent': {'id': vidcomments0[m]['snippet']['topLevelComment']['id'],\n",
    "                         'authorDisplayName': TextCleansing(vidcomments0[m]['snippet']['topLevelComment']['snippet']['authorDisplayName']),\n",
    "                         'textOriginal': TextCleansing(vidcomments0[m]['snippet']['topLevelComment']['snippet']['textOriginal']),\n",
    "                         'likeCount': vidcomments0[m]['snippet']['topLevelComment']['snippet']['likeCount'],\n",
    "                         'publishedAt': vidcomments0[m]['snippet']['topLevelComment']['snippet']['publishedAt'],\n",
    "                         'updatedAt': vidcomments0[m]['snippet']['topLevelComment']['snippet']['updatedAt']}}}\n",
    "\n",
    "        rply = vidcomments0[m].get('replies')\n",
    "        if rply != None:\n",
    "            rplL = rply['comments']\n",
    "            for rp in rplL:\n",
    "                rplyDict = {'Output1' : {'reply':  {'etag': rp.get('etag'), 'id': rp.get('id'),\n",
    "                                                    'videoId': rp.get('snippet').get('videoId'),\n",
    "                                                    'textOriginal': TextCleansing(rp.get('snippet').get('textOriginal')),\n",
    "                                                    'parentId': rp.get('snippet').get('parentId'),\n",
    "                                                    'authorDisplayName': TextCleansing(rp.get('snippet').get('authorDisplayName')),\n",
    "                                                    'likeCount': rp.get('snippet').get('likeCount'),\n",
    "                                                    'publishedAt': rp.get('snippet').get('publishedAt')}\n",
    "                                        }}\n",
    "                vidCommentsDf0 = vidCommentsDf0.append(rplyDict, ignore_index=True, sort = False)\n",
    "        \n",
    "        vidCommentsDf0 = vidCommentsDf0.append(commentoutput, ignore_index=True, sort = False)\n",
    "    \n",
    "    # 3 - Finalize comments dataframe \n",
    "    vidCommentsDf0['Key1'] = ChannelID01\n",
    "    vidCommentsDf0['Key2'] = vidID0  \n",
    "    \n",
    "    # 4 - Return comments dataframe per video\n",
    "    \n",
    "    return vidCommentsDf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "447f1cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** UC_vhdXDVvZQGMqQFDgn0w1g \n",
      "start\t 2021-08-02 16:23:10.000945\n",
      "end\t 2021-08-02 16:25:17.223360\n",
      "*** UCwKZnJ48oXRCCGCQbL1BPSA \n",
      "start\t 2021-08-02 16:25:17.223360\n",
      "end\t 2021-08-02 16:25:49.036331\n"
     ]
    }
   ],
   "source": [
    "chList = df1.Key1.drop_duplicates().values.tolist()\n",
    "videoCommentsDF = pd.DataFrame()\n",
    "\n",
    "for ChannelID in chList:\n",
    "    print('***', str(ChannelID), '\\nstart\\t', datetime.now())\n",
    "    videoIdList = df1['Key2'][df1.Key1 == ChannelID].drop_duplicates().values.tolist()\n",
    "    \n",
    "    x = 1    \n",
    "    vidcommDF = pd.DataFrame()    \n",
    "    for vidID in videoIdList:\n",
    "        \n",
    "        vidcommDF = CommentsDataPerVideoID(vidID, ChannelID)\n",
    "        videoCommentsDF = videoCommentsDF.append(vidcommDF, ignore_index = True)\n",
    "        \n",
    "        if (x % 100 == 0):\n",
    "            time.sleep(3)\n",
    "        \n",
    "        x = x + 1\n",
    "    \n",
    "    YToutputCommDF = PrepareOutputDF('K12', videoCommentsDF, 'Automatic', 'VideoComments-YouTube')\n",
    "    \n",
    "    # Write and store channel video list, video details and comments\n",
    "    DF = pd.read_csv('C:/Users/Esteban Guerrero/SocialNetworkProject/Iteration2/Datasets/NetworkFeedRawOutput.csv', index_col = False, encoding = 'ISO-8859-1')\n",
    "    DF = DF.append([YToutputCommDF], ignore_index=True)\n",
    "    DF.to_csv('C:/Users/Esteban Guerrero/SocialNetworkProject/Iteration2/Datasets/NetworkFeedRawOutput.csv', index = False)\n",
    "    \n",
    "    print('end\\t', datetime.now()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
