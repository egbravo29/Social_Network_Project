{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4f4494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import os\n",
    "\n",
    "# YouTube API\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806fe8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain list of YouTube profile IDs\n",
    "df1 = pd.read_excel('C:/Users/Esteban Guerrero/SocialNetworkProject/Iteration2/Datasets/MasterDataExtract.xlsx', dtype = object)\n",
    "df1 = df1[(df1.Plattform == 'YouTube') & (df1.KeySearchType == 'ProfileID')]\n",
    "YTProfileList = df1.KeySearch.values.tolist()\n",
    "YTAliasList = df1.Alias.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f7ba9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os. chdir('C:/Users/Esteban Guerrero/SocialNetworkProject/Iteration2/PythonScripts')\n",
    "%run ./DataProcessing_PrepareOutputIntoDF.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e737358e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os. chdir('C:/Users/Esteban Guerrero/SocialNetworkProject/Iteration2/PythonScripts')\n",
    "%run ./DataProcessing_TextPreparation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7633008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize API\n",
    "youTubeApiKey = 'AIzaSyBoy7og8QhXwBnFb5LC-7LC8c5ygQaVCUI'\n",
    "youtube = build('youtube','v3', developerKey = youTubeApiKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2076cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract from API, video data per channel and return video dataframe and video list\n",
    "\n",
    "def VideoDataPerChannel(ChannelID0, ChAlias0):\n",
    "    \n",
    "    # 1 - Extract list of videos uploaded to channel per ChannelID0\n",
    "    uploadYT = youtube.channels().list(id = ChannelID0, part = 'contentDetails').execute()\n",
    "    playlist_id = uploadYT['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    \n",
    "    # 2 - Extract from API details of videos per playlist_id\n",
    "    videos0 = []\n",
    "    next_page_token = None\n",
    "    while 1:\n",
    "        res = youtube.playlistItems().list(playlistId = playlist_id, part = 'snippet',\n",
    "                                           maxResults = 50, pageToken = next_page_token).execute()\n",
    "        videos0 += res['items']\n",
    "        next_page_token = res.get('nextPageToken')\n",
    "\n",
    "        if next_page_token is None:\n",
    "            break\n",
    "        \n",
    "    # 3 - Create video list and dataframe and select relevant video fields\n",
    "    videodf0 = pd.DataFrame()\n",
    "    videoIdList0 = []\n",
    "    for i in range(0, len(videos0)):\n",
    "        outputRow = {'videoID': videos0[i]['snippet']['resourceId']['videoId'],\n",
    "                  'vidDetails': {'publishedAt': videos0[i]['snippet']['publishedAt'],\n",
    "                  'title': TextCleansing(videos0[i]['snippet']['title'])}}\n",
    "        videoIdList0.append(videos0[i]['snippet']['resourceId']['videoId'])\n",
    "        videodf0 = videodf0.append(outputRow, ignore_index=True)    \n",
    "    \n",
    "    # 4 - Extract from API statistics of videos per video ID\n",
    "    vidStatsList0 = []\n",
    "    for j in range(0, len(videoIdList0), 40):\n",
    "        res = (youtube).videos().list(id = ','.join(videoIdList0[j:j+40]),part='statistics').execute()\n",
    "        vidStatsList0 += res['items']\n",
    "    \n",
    "    # 5 - Create video statistics dataframe\n",
    "    vidStatsDf0 = pd.DataFrame()\n",
    "    for k in range(0, len(vidStatsList0)):\n",
    "        vidStatsDf0 = vidStatsDf0.append({'videoId': vidStatsList0[k]['id'], \n",
    "                                        'vidStats': vidStatsList0[k]['statistics']}, \n",
    "                                       ignore_index=True, sort = False)\n",
    "        \n",
    "    # 6 - Prepare dataframe with video details and video statistics\n",
    "    \n",
    "    videodf0 = pd.merge(videodf0, vidStatsDf0, left_on = 'videoID', right_on = 'videoId', how = 'left').drop('videoId', axis = 1)\n",
    "    videodf0['Key1'] = ChannelID0\n",
    "\n",
    "    videodf0.rename(columns = {'videoID': 'Key2'}, inplace = True)\n",
    "    videodf0['Output1'] = ''\n",
    "    \n",
    "    indexOutput1 = videodf0.columns.get_loc('Output1')\n",
    "    indexVidDet = videodf0.columns.get_loc('vidDetails')\n",
    "    indexVidStats = videodf0.columns.get_loc('vidStats')\n",
    "    \n",
    "    for m in range(0, len(videodf0.Key2)):\n",
    "        videodf0.iat[m, indexOutput1] = {'User': ChAlias0, 'VideoDetails': videodf0.iat[m, indexVidDet],\n",
    "                        'VideoStats': videodf0.iat[m, indexVidStats]}\n",
    "\n",
    "    \n",
    "    videodf0.drop(columns = ['vidDetails', 'vidStats'], inplace = True)\n",
    "    \n",
    "    # 7 - Prepare dataframe with channel video list\n",
    "    \n",
    "    chlistdf = pd.DataFrame()\n",
    "    chlistdict = {'Output1': {'User': ChAlias0, 'VideoList': videoIdList0}, 'Key1': ChannelID0, 'Key2': playlist_id}\n",
    "    chlistdf = chlistdf.append(chlistdict, ignore_index = True)\n",
    "    \n",
    "    \n",
    "    # 8 - Append video details and video list and return video dataframe\n",
    "      \n",
    "    return videodf0, chlistdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58144e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Milei \n",
      "start\t 2021-08-02 16:22:03.325369\n",
      "end\t 2021-08-02 16:22:05.642411\n",
      "*** Espert \n",
      "start\t 2021-08-02 16:22:05.643411\n",
      "end\t 2021-08-02 16:22:28.833254\n",
      "*** PLibCABA \n",
      "start\t 2021-08-02 16:22:28.833254\n",
      "end\t 2021-08-02 16:22:30.304392\n"
     ]
    }
   ],
   "source": [
    "videosDF = pd.DataFrame()\n",
    "videoListDF = pd.DataFrame()\n",
    "j = 0\n",
    "for YTProfile in YTProfileList:\n",
    "    print('***', YTAliasList[j], '\\nstart\\t', datetime.now())\n",
    "    videodf, videolistdf = VideoDataPerChannel(YTProfile, YTAliasList[j])\n",
    "    videosDF = videosDF.append(videodf, ignore_index = True)\n",
    "    videoListDF = videoListDF.append(videolistdf, ignore_index = True)\n",
    "    j = j + 1\n",
    "    print('end\\t', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57892cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "YToutputVidDF = PrepareOutputDF('K12', videosDF, 'Automatic', 'VideoInfo-YouTube')\n",
    "YToutputListDF = PrepareOutputDF('K12', videoListDF, 'Automatic', 'VideoList-YouTube')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "507888ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and store channel video list, video details and comments\n",
    "DF = pd.read_csv('C:/Users/Esteban Guerrero/SocialNetworkProject/Iteration2/Datasets/NetworkFeedRawOutput.csv', index_col = False, encoding = 'ISO-8859-1')\n",
    "DF = DF.append([YToutputVidDF, YToutputListDF], ignore_index=True)\n",
    "DF.to_csv('C:/Users/Esteban Guerrero/SocialNetworkProject/Iteration2/Datasets/NetworkFeedRawOutput.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
